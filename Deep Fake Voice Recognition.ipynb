{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecfc5d4-a62e-40e8-8cf7-7016af37faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install resampy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf45dc0-d37f-447b-ad5e-340514824ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import IPython\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8da9c52-9ae5-418f-a159-ee6d3292f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files_path = \"C:/Users/Akshay Ransure/Documents/fahad/Deep Fake Voice Recognition/data_deep_voice/KAGGLE/AUDIO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5cbac0-ad6e-41d7-beed-1da6faf9de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir(audio_files_path)\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df9256-e9ef-4a38-99be-4542cb4945a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_audio = \"C:/Users/Akshay Ransure/Documents/fahad/Deep Fake Voice Recognition/data_deep_voice/DEMONSTRATION/DEMONSTRATION/linus-original-DEMO.mp3\"\n",
    "fake_audio = \"C:/Users/Akshay Ransure/Documents/fahad/Deep Fake Voice Recognition/data_deep_voice/DEMONSTRATION\\DEMONSTRATION/linus-to-musk-DEMO.mp3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1272b68-3407-4dd4-88fa-73cc38e9ec71",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7563698a-cbb7-427f-9dd7-d634cab1ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Real Audio:\")\n",
    "IPython.display.Audio(real_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ef346a-5781-45f3-affa-b050d6be27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fake Audio:\")\n",
    "IPython.display.Audio(fake_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6419904d-1a18-4340-a226-0601fa67ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_ad, real_sr = librosa.load(real_audio)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(real_ad)\n",
    "plt.title(\"Real Audio Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f28f541-5ffa-453a-a04f-57b94f2a3054",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_spec = np.abs(librosa.stft(real_ad))\n",
    "real_spec = librosa.amplitude_to_db(real_spec, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(real_spec, sr=real_sr, x_axis=\"time\", y_axis=\"log\")\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"Real Audio Spectogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f76a245-9203-4749-8eae-d4c060d089b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_mel_spect = librosa.feature.melspectrogram(y=real_ad, sr=real_sr)\n",
    "real_mel_spect = librosa.power_to_db(real_mel_spect, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(real_mel_spect, y_axis=\"mel\", x_axis=\"time\")\n",
    "plt.title(\"Real Audio Mel Spectogram\")\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d392f30-03f0-43a6-9862-3034c84d63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_chroma = librosa.feature.chroma_cqt(y=real_ad, sr=real_sr, bins_per_octave=36)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(real_chroma, sr=real_sr, x_axis=\"time\", y_axis=\"chroma\", vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title(\"Real Audio Chromagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec86b4e-a10f-4769-b9aa-327906600b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_mfccs = librosa.feature.mfcc(y=real_ad, sr=real_sr)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(real_mfccs, sr=real_sr, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Real Audio Mel-Frequency Cepstral Coefficients (MFCCs)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1aa2e7-40ae-42c2-ba9c-d69a57009d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_ad, fake_sr = librosa.load(fake_audio)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(fake_ad)\n",
    "plt.title(\"Fake Audio Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633d2211-1926-4986-9a2f-cc07e30b2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_spec = np.abs(librosa.stft(fake_ad))\n",
    "fake_spec = librosa.amplitude_to_db(fake_spec, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(fake_spec, sr=fake_sr, x_axis=\"time\", y_axis=\"log\")\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"Fake Audio Spectogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e6bce-f286-41ca-aed2-0dd01e474819",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_mel_spect = librosa.feature.melspectrogram(y=fake_ad, sr=fake_sr)\n",
    "fake_mel_spect = librosa.power_to_db(fake_mel_spect, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(fake_mel_spect, y_axis=\"mel\", x_axis=\"time\")\n",
    "plt.title(\"Fake Audio Mel Spectogram\")\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b21768-be3a-47cd-8c4e-97e48f5c73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_chroma = librosa.feature.chroma_cqt(y=fake_ad, sr=fake_sr, bins_per_octave=36)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(fake_chroma, sr=fake_sr, x_axis=\"time\", y_axis=\"chroma\", vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title(\"Fake Audio Chromagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a2485-1ac8-40fa-bbae-18dd9b1ac2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_mfccs = librosa.feature.mfcc(y=fake_ad, sr=fake_sr)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(fake_mfccs, sr=fake_sr, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Fake Audio Mel-Frequency Cepstral Coefficients (MFCCs)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8edc53b-d77d-474c-ae44-61a40b8938ae",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9005af9e-2d98-469b-a1cb-f9b37f9b3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(audio_files_path, folder))\n",
    "    for file in tqdm(files):\n",
    "        file_path = os.path.join(audio_files_path, folder, file)\n",
    "        audio, sample_rate = librosa.load(file_path, res_type=\"kaiser_fast\")\n",
    "        mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_features_scaled = np.mean(mfccs_features.T, axis=0)\n",
    "        data.append(mfccs_features_scaled)\n",
    "        labels.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1211951e-0449-4ed1-a927-049cd1d79551",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame({\"features\": data, \"class\": labels})\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a3ee7c-5e3c-4ca7-b2a9-18ac40d8bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a346d-b1d0-4778-89f6-c58f75317868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(column):\n",
    "    le = LabelEncoder().fit(column)\n",
    "    print(column.name, le.classes_)\n",
    "    return le.transform(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f271fd55-fe2b-4187-9944-6bf4eab5a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df[\"class\"] = label_encoder(feature_df[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696548cb-0a30-4a5f-a22f-4aa61dd00c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(feature_df[\"features\"].tolist())\n",
    "y = np.array(feature_df[\"class\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6931b3e-5925-4510-a5c3-a1c469308830",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e9572-3dce-46aa-85d0-cbafb96710b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resampled = to_categorical(y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98549ee-b10b-4a16-9885-c0141594dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817e010-8433-43e2-96a4-0fbefa78af53",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(feature_df[\"class\"].unique())\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207009d1-49b8-4c2e-9639-170954079501",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = feature_df[\"features\"][0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fb96ab-a9da-4ed0-9ce5-f4b43472f5d7",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e118267-0a49-4a3d-bc11-6ae9c877f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=input_shape))\n",
    "model.add(Activation(activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation(activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe2207e-7b97-445c-b3e1-f781aa36e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842d385-3047-40f0-b78c-a9bdfa338b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b217f9-c23a-4d59-8bed-b45b202f1c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early = EarlyStopping(monitor=\"val_loss\", patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86249d3f-d9e8-45ce-b397-189039fdecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=2, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f448e1c1-8575-4e09-9a4f-08a62518f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a346a0b-730e-44ea-855b-ee354d0cbe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"validation\")\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e007b-c741-4e24-b2bd-03d4c7ea0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Model Loss\")\n",
    "plt.plot(history.history[\"loss\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"validation\")\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82d8e2-3d75-4bf3-9d15-9c5143c44f1d",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c5ef31-6c09-41af-b459-dc983a3df809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_fake(filename):\n",
    "    sound_signal, sample_rate = librosa.load(filename, res_type=\"kaiser_fast\")\n",
    "    mfcc_features = librosa.feature.mfcc(y=sound_signal, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_features_scaled = np.mean(mfcc_features.T, axis=0)\n",
    "    mfccs_features_scaled = mfccs_features_scaled.reshape(1, -1)\n",
    "    result_array = model.predict(mfccs_features_scaled)\n",
    "    print(result_array)\n",
    "    result_classes = [\"FAKE\", \"REAL\"]\n",
    "    result = np.argmax(result_array[0])\n",
    "    print(\"Result:\", result_classes[result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baf27b5-218b-4b93-94f9-c7f2fda1aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_real = \"C:/Users/Akshay Ransure/Documents/fahad/Deep Fake Voice Recognition/data_deep_voice/KAGGLE/AUDIO/REAL/obama-original.wav\"\n",
    "test_fake = \"C:/Users/Akshay Ransure/Documents/fahad/Deep Fake Voice Recognition/data_deep_voice/KAGGLE/AUDIO/FAKE/Obama-to-Biden.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c0162e-eab0-42ae-aa8e-ef5f77ebbd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_fake(test_real)\n",
    "IPython.display.Audio(test_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b3b4e-0750-4f82-b558-27cc2ceabddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_fake(test_fake)\n",
    "IPython.display.Audio(test_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224bdf0e-ef3d-4463-8ec6-342602fa3c72",
   "metadata": {},
   "source": [
    "# Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f7733a-b753-47a8-99ff-34831f56fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open(r\"C:/Users/Akshay Ransure/Documents/fahad/Deep Fake Voice Recognition/build.h5\",'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4b711-4849-442f-a1b2-9af807aae599",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a07fd-5a26-4a1f-a169-a38383c78bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8903a-3340-4836-bb3e-a20a9e3bb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
